{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seismic Stack SEG-Y Import\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, you will need the segpy package to read SEGY files. Use pip to install this package.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import colors, cm, pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "#np.set_printoptions(linewidth=120)\n",
    "\n",
    "import colorsys as cs\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from PIL import Image\n",
    "\n",
    "from segpy.reader import create_reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function to that will readin seismic data in SEGY format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(segy_file, line_type='crossline_number'):\n",
    "    # read in SEGY file\n",
    "    lines = []\n",
    "    lines_id = []\n",
    "    lines_id_unique = []\n",
    "    line_length = []\n",
    "    line_counter = 0\n",
    "    \n",
    "    with open(segy_file, 'rb') as in_file:\n",
    "        segy_reader = create_reader(in_file)\n",
    "        for i in segy_reader.trace_indexes():\n",
    "            trace = segy_reader.trace_samples(i)\n",
    "            header = segy_reader.trace_header(i)\n",
    "            lines.append(list(trace))\n",
    "            if line_type=='crossline_number':          #chose line_type according to the data \n",
    "                header_loc = header.crossline_number\n",
    "            else:\n",
    "                header_loc = header.inline_number\n",
    "                \n",
    "            lines_id.append(header_loc)\n",
    "            \n",
    "            # keep track of unique line IDs, assume that shots are sorted contiguously\n",
    "            if header_loc not in lines_id_unique:\n",
    "                lines_id_unique.append(header_loc)\n",
    "                line_length.append(0)\n",
    "                line_counter += 1\n",
    "            line_length[line_counter-1] += 1\n",
    "\n",
    "    lines_id = np.asarray(lines_id, dtype=int)\n",
    "    line_length = np.asarray(line_length, dtype=int)\n",
    "    lines_id_unique = np.asarray(lines_id_unique, dtype=int)\n",
    "    lines = np.asarray(lines, dtype=float)\n",
    "\n",
    "    return lines, line_length, lines_id_unique, lines_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in SEGY files\n",
    "line_type = 'crossline_number'\n",
    "path_train_img = \"F:/.......\"\n",
    "lines, line_length, lines_id_unique, lines_id = read_lines(path_train_img, line_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traces and samples: (72440, 480)\n",
      "Num_samples: 480\n",
      "Number of Crosslines: (70,)\n",
      "Each lines has different number of traces: \n",
      " [ 762  762  762  916  938  938 1061 1108 1505 1504 1460 1405 1405 1405 1404\n",
      " 1500 1500 1499 1498 1451 1295 1199 1152 1105 1065 1058 1056 1068 1087 1139\n",
      " 1186 1186 1186 1186 1177 1157 1148 1148 1148 1148  962  963  965  797  799\n",
      "  799  801  802  803  804  805  806  807  808  808  810  810  812  812  814\n",
      "  814  816  816  818  818  820  819  819  818  818] \n",
      "\n",
      "Crossline id:\n",
      " [11801 11901 12001 12101 12201 12301 12401 12501 12601 12701 12801 12901\n",
      " 13001 13101 13201 13301 13401 13501 13601 13701 13801 13901 14001 14101\n",
      " 14201 14301 14401 14501 14601 14701 14801 14901 15001 15101 15201 15301\n",
      " 15401 15501 15601 15701 15801 15901 16001 16101 16201 16301 16401 16501\n",
      " 16601 16701 16801 16901 17001 17101 17201 17301 17401 17501 17601 17701\n",
      " 17801 17901 18001 18101 18201 18301 18401 18501 18601 18701] \n",
      "\n",
      "Line id: (72440,) \n",
      " [11801 11801 11801 ..., 18701 18701 18701]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of traces and samples:\", lines.shape)\n",
    "print(\"Num_samples:\",len(lines[1]))\n",
    "print(\"Number of Crosslines:\", line_length.shape)\n",
    "print(\"Each lines has different number of traces: \\n\", line_length, \"\\n\")\n",
    "print(\"Crossline id:\\n\", lines_id_unique, \"\\n\")\n",
    "print(\"Line id:\",lines_id.shape, \"\\n\", lines_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing a seismic image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(lines[0:761], (1,0)), cmap='Greys', origin='upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an array of seismic images\n",
    "### All the 2D images are combined into a big array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = lines_to_imgs(lines, line_length, lines_id_unique, lines_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final array is of shape  (115, 480, 480)\n"
     ]
    }
   ],
   "source": [
    "print('Final array is of shape ',images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some addition function to process or munge the images:\n",
    "eg. normalizing training data, clipping the amplitude of the seismic traces, \n",
    "convert seismic image array to RGB, color saturation etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_imgs(train_data):\n",
    "\n",
    "    mean = np.mean(train_data, axis=(1,2))  # mean for data centering\n",
    "    std = np.std(train_data, axis=(1,2))  # std for data normalization\n",
    "    train_data_norm = train_data\n",
    "    for i in range(len(train_data)):\n",
    "        train_data_norm[i] = np.subtract(train_data[i], mean[i])\n",
    "        train_data_norm[i] /= std[i]\n",
    "        \n",
    "    return train_data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_traces_vgg(shots, clip_value):\n",
    "    # clips, re-scale and re-mean traces to make it compatible with VGGNet\n",
    "    # note that values are still single precision floating point numbers (float32), even though it has the same range as uint8\n",
    "    clip_value = np.abs(clip_value)\n",
    "\n",
    "    output = np.clip(shots, a_min=-clip_value, a_max=clip_value)\n",
    "\n",
    "    # scale to twice of clip value, assuming data has mean of zero\n",
    "    output = (output + clip_value) / (2.0 * clip_value)\n",
    "\n",
    "    return 255 * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seismic_to_RGB(line, shift_value=1):\n",
    "    num_imgs = np.size(line, axis=0)\n",
    "    img_rows = np.size(line, axis=1)\n",
    "    img_cols = np.size(line, axis=2)\n",
    "\n",
    "    line_up = np.zeros((num_imgs, img_rows, img_cols), dtype=float)\n",
    "    line_down = np.zeros((num_imgs, img_rows, img_cols), dtype=float)\n",
    "\n",
    "    for i in range(0, num_imgs):\n",
    "        for k in range(0, img_rows):\n",
    "            line_up[i, k, :] = shift(line[i, k, :], shift_value, cval=0)\n",
    "            line_down[i, k, :] = shift(line[i, k, :], -shift_value, cval=0)\n",
    "\n",
    "\n",
    "    line_RGB = np.stack((line_down, line, line_up), axis=-1).astype(np.float32)\n",
    "    print('Original shape: ', line.shape)\n",
    "    print('New shape: ', line_RGB.shape)\n",
    "    return line_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeismicRGB_to_Saturation(line_RGB):\n",
    "    num_imgs = np.size(line_RGB, axis=0)\n",
    "    img_rows = np.size(line_RGB, axis=1)\n",
    "    img_cols = np.size(line_RGB, axis=2)\n",
    "\n",
    "    Temp_HSV = np.zeros((num_imgs,img_rows,img_cols,3), dtype=float)\n",
    "\n",
    "\n",
    "    for i in range(num_imgs):\n",
    "\n",
    "        im_temp = Image.fromarray(line_RGB[i].astype(np.uint8), mode='RGB')\n",
    "        Temp_HSV[i] = np.array(im_temp.convert(mode='HSV'))\n",
    "\n",
    "    Saturation = np.zeros((num_imgs,img_rows,img_cols), dtype=float)\n",
    "    \n",
    "    Saturation = Temp_HSV[:,:,:,2]\n",
    "\n",
    "    return Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a saturated line from the array\n",
    "\n",
    "RGB_Sat = SeismicRGB_to_Saturation(Image_RGB)\n",
    "plt.imshow(np.transpose(RGB_Sat[60],(1,0)).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
